{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import Ollama\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader  # Correct import for PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma  # Correct import for Chroma\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate  # Import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_14280\\1731421316.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"mistral\", base_url=\"http://127.0.0.1:11434\")\n"
     ]
    }
   ],
   "source": [
    "# Définir le modèle LLM Mistral\n",
    "llm = Ollama(model=\"mistral\", base_url=\"http://127.0.0.1:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_14280\\3927695981.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embed_model = OllamaEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Définir le modèle d'embedding Mistral\n",
    "embed_model = OllamaEmbeddings(\n",
    "    model=\"mistral\",\n",
    "    base_url='http://127.0.0.1:11434'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier PDF\n",
    "pdf_path = \"cv_ilyass_ouzzou.pdf\"\n",
    "loader = PyMuPDFLoader(pdf_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser le texte du PDF en morceaux\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=128)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un répertoire pour la persistance de la base de données vectorielle\n",
    "persist_directory = \"persisted_db\"\n",
    "os.makedirs(persist_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un store de vecteurs avec persistance\n",
    "vector_store = Chroma.from_documents(\n",
    "    chunks, embed_model, persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurer le récupérateur\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\anaconda3\\Lib\\site-packages\\langsmith\\client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Créer la chaîne de récupération\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un prompt template structuré\n",
    "formatted_prompt = \"\"\"\n",
    "Si une réponse peut être trouvée à partir des documents fournis, donnez-la. \n",
    "Si aucune réponse pertinente n'est disponible dans les documents, répondez en utilisant le modèle LLM Mistral uniquement.\n",
    "Contexte: {context}\n",
    "Question: {question}\n",
    "Réponse:\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser PromptTemplate pour créer un objet de prompt\n",
    "prompt_template = PromptTemplate(input_variables=[\"context\", \"question\"], template=formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer la chaîne de récupération avec un modèle de combinaison des documents\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm, prompt_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer la chaîne de récupération complète\n",
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Les changements climatiques sont un phénomène global lié aux variations du climat sur une période de longue durée. Ces changements peuvent être naturels, comme les cycles du glacial et interglaciaire, mais l'impact humain sur l'environnement est actuellement considéré comme une cause importante des changements climatiques contemporains. On parle souvent de \"changement climatique anthropocène\" pour désigner cette période. Les conséquences du changement climatique peuvent inclure l'augmentation moyenne de la température, les modifications des précipitations, le niveau plus haut de la mer et l'élévation du risque de phénomènes extrêmes tels que les ouragans et les inondations. Les changements climatiques ont un impact sur la biodiversité, l'économie et la santé humaine.\n"
     ]
    }
   ],
   "source": [
    "# Tester avec une question (remplacer 'context' par 'input' dans l'appel)\n",
    "response = retrieval_chain.invoke({\"input\": \"Voici le contexte des documents\", \"question\": \"c'est quoi les changement climatique\"})\n",
    "print(response['answer'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
